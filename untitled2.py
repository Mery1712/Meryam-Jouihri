# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CEz5OdxC2IqKsPYAAoBZzH6FrKSEMAlL
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
import os
import requests
import zipfile

# Téléchargement et extraction des données
# Définir les chemins des fichiers
zip_file = "ml-10M100K.zip"
ratings_file = "ml-10M100K/ratings.dat"
movies_file = "ml-10M100K/movies.dat"

# Télécharger le fichier si non présent
if not os.path.exists(zip_file):
    url = "https://files.grouplens.org/datasets/movielens/ml-10m.zip"
    r = requests.get(url)
    with open(zip_file, "wb") as f:
        f.write(r.content)

# Extraire les fichiers
with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall()

# Chargement des données
# Lire les fichiers ratings et movies
ratings = pd.read_csv(ratings_file, delimiter='::', engine='python',
                      names=['userId', 'movieId', 'rating', 'timestamp'])
movies = pd.read_csv(movies_file, delimiter='::', engine='python',
                     names=['movieId', 'title', 'genres'])

# Convertir les colonnes nécessaires en types appropriés
ratings['userId'] = ratings['userId'].astype(int)
ratings['movieId'] = ratings['movieId'].astype(int)
ratings['rating'] = ratings['rating'].astype(float)
ratings['timestamp'] = ratings['timestamp'].astype(int)
movies['movieId'] = movies['movieId'].astype(int)

# Fusion des données
movielens = pd.merge(ratings, movies, on='movieId')

# Division des données en ensembles edx et final_holdout_test
edx, temp = train_test_split(movielens, test_size=0.1, random_state=1)
final_holdout_test = temp[(temp['movieId'].isin(edx['movieId'])) & (temp['userId'].isin(edx['userId']))]
edx = pd.concat([edx, temp[~temp.index.isin(final_holdout_test.index)]])
del ratings, movies, temp

"""2. Analyse exploratoire des données (EDA)

a. Visualisation de la distribution des notes
"""

# Distribution des notes
plt.figure(figsize=(8, 5))
sns.histplot(movielens['rating'], bins=10, kde=False)
plt.title('Distribution des notes')
plt.xlabel('Note')
plt.ylabel('Nombre de votes')
plt.grid(True)
plt.show()

"""b. Nombre de films par genre

"""

# Nombre de films par genre
genre_count = movielens['genres'].str.get_dummies(sep='|').sum().sort_values(ascending=False)
genre_count.plot(kind='bar', figsize=(12, 6))
plt.title('Nombre de films par genre')
plt.xlabel('Genre')
plt.ylabel('Nombre de films')
plt.grid(True)
plt.show()

"""c. Moyenne des notes par genre

"""

# Moyenne des notes par genre
genre_avg_rating = movielens.groupby('genres')['rating'].mean().sort_values(ascending=False)
genre_avg_rating.plot(kind='bar', figsize=(12, 6))
plt.title('Moyenne des notes par genre')
plt.xlabel('Genre')
plt.ylabel('Moyenne des notes')
plt.grid(True)
plt.show()

# Fonction pour extraire l'année du titre du film
def extract_year(title):
    year = title.strip()[-5:-1]
    if year.isdigit():
        return int(year)
    else:
        return pd.NA

# Ajouter l'année de sortie du film
movielens['release_year'] = movielens['title'].apply(extract_year)

# Statistiques utilisateur
user_stats = movielens.groupby('userId')['rating'].agg(['mean', 'count']).reset_index()
user_stats.columns = ['userId', 'user_mean_rating', 'user_rating_count']

# Statistiques des films
movie_stats = movielens.groupby('movieId')['rating'].agg(['mean', 'count']).reset_index()
movie_stats.columns = ['movieId', 'movie_mean_rating', 'movie_rating_count']

# Joindre ces statistiques à l'ensemble de données movielens
movielens = movielens.merge(user_stats, on='userId', how='left')
movielens = movielens.merge(movie_stats, on='movieId', how='left')

# Extraction des genres
unique_genres = set()
for genre_list in movielens['genres'].str.split('|'):
    unique_genres.update(genre_list)
unique_genres = list(unique_genres)

# Ajouter une colonne pour chaque genre
for genre in unique_genres:
    movielens[genre] = movielens['genres'].apply(lambda x: 1 if genre in x else 0)

# Vérifier les premières lignes du DataFrame pour s'assurer que les nouvelles colonnes sont ajoutées
print(movielens.head())

from sklearn.preprocessing import StandardScaler

# Sélection des colonnes à normaliser
columns_to_normalize = ['user_mean_rating', 'user_rating_count', 'movie_mean_rating', 'movie_rating_count']

# Initialisation du standard scaler
scaler = StandardScaler()

# Appliquer le scaler sur les colonnes sélectionnées
movielens[columns_to_normalize] = scaler.fit_transform(movielens[columns_to_normalize])

# Vérification des résultats
print(movielens[columns_to_normalize].head())

import numpy as np  # Assurez-vous que numpy est importé
import seaborn as sns
import matplotlib.pyplot as plt

# Sélection des colonnes numériques uniquement
numeric_features = movielens.select_dtypes(include=[np.number])

# Calcul de la matrice de corrélation
corr_matrix = numeric_features.corr()

# Affichage de la heatmap avec des améliorations pour la clarté
plt.figure(figsize=(14, 10))  # Augmenter la taille de la figure pour plus de clarté

# Définir un style de fond pour rendre les annotations plus visibles
sns.set(style='white')

# Création de la heatmap
heatmap = sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',
                      center=0, linewidths=0.5, linecolor='gray',
                      annot_kws={"size": 10},  # Taille des annotations
                      cbar_kws={"shrink": .8})  # Taille de la barre de couleur

# Titre et labels
plt.title('Matrice de Corrélation des Caractéristiques', size=16)
plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotation des labels des colonnes
plt.yticks(rotation=0, fontsize=12)  # Rotation des labels des lignes
plt.show()

